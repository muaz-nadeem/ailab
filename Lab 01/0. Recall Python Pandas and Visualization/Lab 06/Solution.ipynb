{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "852d878d-67f8-4898-bc71-f97750c82112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43607db2-57a5-4203-b09e-2f0b4867cd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(91, 'English'), (45, 'French'), (25, 'Arabic'), (24, 'Spanish'), (9, 'Russian'), (9, 'Portuguese'), (8, 'Dutch'), (7, 'German'), (5, 'Chinese'), (4, 'Swahili')]\n"
     ]
    }
   ],
   "source": [
    "def most_spoken_languages(filename, n):\n",
    "    \"\"\"\n",
    "    Reads a JSON file, counts occurrences of each language,\n",
    "    and returns the n most spoken languages in descending order.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    language_counts = {}\n",
    "    for country in data:\n",
    "        for lang in country['languages']:\n",
    "            if lang in language_counts:\n",
    "                language_counts[lang] += 1\n",
    "            else:\n",
    "                language_counts[lang] = 1\n",
    "    \n",
    "    sorted_languages = []\n",
    "    for key, value in language_counts.items():\n",
    "        sorted_languages.append((value, key))\n",
    "    sorted_languages.sort(reverse=True)\n",
    "    \n",
    "    return sorted_languages[:n]\n",
    "\n",
    "print(most_spoken_languages(\"./data/countries_data.json\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b27b025-0618-4d49-9b7e-34f2777075ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'country': 'China', 'population': 1377422166}, {'country': 'India', 'population': 1295210000}, {'country': 'United States of America', 'population': 323947000}, {'country': 'Indonesia', 'population': 258705000}, {'country': 'Brazil', 'population': 206135893}, {'country': 'Pakistan', 'population': 194125062}, {'country': 'Nigeria', 'population': 186988000}, {'country': 'Bangladesh', 'population': 161006790}, {'country': 'Russian Federation', 'population': 146599183}, {'country': 'Japan', 'population': 126960000}]\n"
     ]
    }
   ],
   "source": [
    "def most_populated_countries(filename, n):\n",
    "    \"\"\"\n",
    "    Reads a JSON file, sorts countries by population,\n",
    "    and returns the n most populated countries.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        for j in range(i + 1, len(data)):\n",
    "            if data[i]['population'] < data[j]['population']:\n",
    "                data[i], data[j] = data[j], data[i]\n",
    "    \n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append({\"country\": data[i]['name'], \"population\": data[i]['population']})\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(most_populated_countries(\"./data/countries_data.json\", 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07c87e66-4223-4a44-af59-fa6a89ae2a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Similarity Score: 0.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def check_text_similarity(file1, file2, stop_words_file):\n",
    "    \"\"\"\n",
    "    Computes the Jaccard similarity between two text files after removing stop words.\n",
    "    \"\"\"\n",
    "    with open(\"Data/stop_words.txt\", 'r', encoding='utf-8') as file:\n",
    "        stop_words = set(file.read().splitlines())\n",
    "    \n",
    "    def clean_text(text):\n",
    "        for char in \"!@#$%^&*()_+-=<>?/.,;:'\\\"{}[]|\\\\\":\n",
    "            text = text.replace(char, \" \")\n",
    "        words = text.lower().split()\n",
    "        cleaned_words = []\n",
    "        for word in words:\n",
    "            if word not in stop_words:\n",
    "                cleaned_words.append(word)\n",
    "        return cleaned_words\n",
    "    \n",
    "    def jaccard_similarity(text1, text2):\n",
    "        set1, set2 = set(text1), set(text2)\n",
    "        intersection = len(set1 & set2)\n",
    "        union = len(set1 | set2)\n",
    "        return intersection / union\n",
    "    file1= \"Data/michelle_obama_speech.txt\"\n",
    "    file2=\"Data/melina_trump_speech.txt\"\n",
    "    with open(file1, 'r', encoding='utf-8') as f1, open(file2, 'r', encoding='utf-8') as f2:\n",
    "        words1, words2 = clean_text(f1.read()), clean_text(f2.read())\n",
    "    \n",
    "    return jaccard_similarity(words1, words2)\n",
    "\n",
    "similarity = check_text_similarity(\"michelle_obama_speech.txt\", \"melina_trump_speech.txt\", \"stop_words.txt\")\n",
    "print(f\"Text Similarity Score: {similarity:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15438728-bf37-4957-af1f-cc807a2d83a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
